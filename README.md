# Spotify End-to-End Azure Data Engineering Project

## ğŸ§­ Overview

This project demonstrates how to build a **fully automated, dynamic, and reusable end-to-end data engineering pipeline** using **Azure Data Factory (ADF)**, **Azure Data Lake Storage (ADLS)**, **Azure SQL Database**, and **Azure Databricks** â€” following the **Medallion Architecture**.

The pipeline is **parameter-driven** and supports **incremental loading** with **Change Data Capture (CDC)** logic. It automatically identifies and loads only the new or updated records since the last successful run.  

The overall goal is to create a **scalable, reusable, and secure data ecosystem** that supports real-time ingestion, transformation, and analytics â€” all integrated with **GitHub CI/CD** for automated deployments.

---

## ğŸ—ï¸ Architecture Style: Medallion Architecture

This project is structured around the **Medallion Architecture**, a layered approach that improves data reliability, quality, and traceability within a data lake.

### ğŸ¥‰ Bronze Layer (Raw Data)
- Stores raw, unprocessed data directly from source systems (Azure SQL).
- Preserves full fidelity of source data for audit and recovery.

### ğŸ¥ˆ Silver Layer (Cleaned Data)
- Transforms and validates raw data.
- Handles schema mapping, joins, and basic transformations using **Databricks** and **Delta Live Tables (DLT)**.

### ğŸ¥‡ Gold Layer (Curated Data)
- Stores business-ready, aggregated data optimized for reporting and dashboards (via **Azure Warehouse / Synapse**).

This layered structure ensures data lineage, historical traceability, and reusability across analytics workloads.

---

## â˜ï¸ Azure Resources and Tools Used

| Resource | Purpose |
|-----------|----------|
| **Azure Data Factory (ADF)** | Orchestrates and automates ETL workflows. |
| **Azure Data Lake Storage (ADLS)** | Central repository for Bronze, Silver, and Gold data layers. |
| **Azure SQL Database** | Source system containing structured transactional data. |
| **Azure Databricks** | Handles data transformation and aggregation using Apache Spark. |
| **Delta Live Tables (DLT)** | Automates incremental transformations with lineage and versioning. |
| **Azure Synapse / Fabric Warehouse** | Used for reporting, dashboards, and analytics queries. |
| **Apache Spark** | Provides distributed and scalable data processing. |
| **Azure Key Vault / Managed Identity** | Secures credentials and secrets across services. |
| **GitHub Actions (CI/CD)** | Enables continuous integration and deployment for ADF, Databricks, and configurations. |

---

## âš™ï¸ Step-by-Step Process Flow

### 1. **Setup Phase**
Create all necessary Azure resources:
- Azure Data Factory
- Azure Data Lake Storage
- Azure SQL Database and Server
- Azure Databricks workspace
- Azure Key Vault
- GitHub Repository for CI/CD

Establish linked services:
- **ADF â†”ï¸ ADLS**
- **ADF â†”ï¸ Azure SQL Database**

---

### 2. **Dynamic Parameterized Pipeline**

The pipeline is built to handle multiple tables dynamically using parameters:
- **Table name**
- **Source query**
- **Destination path**
- **CDC date (watermark)**

This approach makes the pipeline reusable, modular, and easy to maintain.

---

### 3. **Incremental Loading Logic**

Incremental loading ensures efficiency by loading only **new or updated data** since the last pipeline execution.  
The logic is controlled by a **cdc.json** file, which stores the latest CDC timestamp.

#### ğŸ”„ Pipeline Activities:
1. **Lookup Activity** â€“ Fetches last CDC value from `cdc.json`.  
2. **Set Variable Activity** â€“ Captures current execution timestamp.  
3. **Copy Data Activity** â€“ Loads delta data from Azure SQL to ADLS.  
4. **If Condition Activity** â€“  
   - If data > 0 rows â†’ update CDC value and overwrite `cdc.json`.  
   - If data = 0 rows â†’ delete empty file created by Copy activity.  
5. **Script Activity** â€“ Extracts maximum CDC for next load.  
6. **Copy Data Activity** â€“ Updates new CDC value in `container/bronze/cdc/cdc.json`.

   <img width="2530" height="1056" alt="image" src="https://github.com/user-attachments/assets/1f34fc70-f7b6-404c-919f-b109764a2587" />
   
   <img width="1952" height="498" alt="image" src="https://github.com/user-attachments/assets/c7044403-6680-4d22-884d-d5567dd183cb" />

   <img width="1630" height="424" alt="image" src="https://github.com/user-attachments/assets/dfb1076b-882a-45be-9378-d80f3a89040b" />

---

## ğŸ§© Technical Architecture Diagram

```text
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Azure SQL Database      â”‚
         â”‚ (Transactional Source)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  Linked Service (SQL â†’ ADF)
                        â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Azure Data Factory (ADF) â”‚
         â”‚  Parameterized Pipeline    â”‚
         â”‚                            â”‚
         â”‚  1. Lookup Last CDC        â”‚
         â”‚  2. Set Current Date       â”‚
         â”‚  3. Copy Incremental Data  â”‚
         â”‚  4. Update CDC JSON        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  Linked Service (ADF â†’ ADLS)
                        â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Azure Data Lake Storage    â”‚
         â”‚    (Medallion Layers)      â”‚
         â”‚                            â”‚
         â”‚  â”œâ”€â”€ Bronze (Raw)          â”‚
         â”‚  â”‚     â””â”€â”€ cdc/cdc.json    â”‚
         â”‚  â”œâ”€â”€ Silver (Cleaned)      â”‚
         â”‚  â””â”€â”€ Gold (Curated)        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚  Databricks (Spark + DLT)
                        â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Azure Databricks         â”‚
         â”‚   Delta Live Tables (DLT)  â”‚
         â”‚   Transform & Merge Data   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Azure Warehouse / BI     â”‚
         â”‚   (Reporting & Analytics)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
